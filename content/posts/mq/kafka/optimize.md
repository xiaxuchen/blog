---
title: "Optimize"
date: 2024-02-09T16:19:09+08:00
draft: true
---

# 生产者优化

## 批处理

对于生产者，默认`linger.ms=0`,因此一旦 RecordAccumlator 中有数据就进行传输，这样会增大网络开销，因此我们可以增大`linger.ms`来进行批量传输，同时设置`batch.size`来控制批的最大大小，默认是 16k。

### 优点

在大数据量情况下增大传输的效率，减少服务器的开销(整体网络请求的次数变少了)

### 缺点

会增大消息发送的延迟

### 问题

- linger.ms 等待的时间是从什么时候开始计时的(猜测是从上一批发送的时间)，那其实消息的发送延迟增加也只是在 linger.ms 以内。

- 但是批处理的情况下，是否要等待所有的数据都能够响应才发送响应回来呢？

## 数据压缩

指定`compress.type`来对数据进行压缩，批处理的时候发送的消息数量更多了

### 问题

- 数据压缩真的可以提高生产者发送的速率吗？首先对于客户端和服务器都有额外的 cpu 开销，在大量数据的情况下，如果 cpu 扛得住，应当有提升效果，但是如果 cpu 扛不住，那么就会适得其反，反而减慢了数据落盘的速度(等待 cpu 或者拖慢其他功能)。

## 增大缓冲区

对于 Kafka 的缓冲区，消息发送到缓冲区，如果是同步发送，仍然是需要等待消息落盘和响应的，而对于异步发送，则只要消息放到了缓冲区，那么就完成了发送，因此能够提高发送效率(通过线程池区发送，而不是开一个线程直接发送)。

因此对于同步发送的场景，缓冲区并不能加快消息的生产。
而对于异步发送的场景，增大缓冲区意味着容纳更多的消息数据，避免在过多分区(单个分区默认 16k 缓冲区)的情况下无法容纳导致批处理策略失效(提早发送)。

### 问题

缓冲区整体是 producer 级别的还是 topic 级别的，应当是 producer 级别的，正常情况下 topic 的分区数量远远无法到达默认 32M 的数据，如果要达到 32M，那么 topic 需要 2048 个分区。

## 配置代码

```
props.put(ProducerConfig.LINGER_MS_CONFIG, 10);
props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16 * 1024);
props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 64 * 1024 * 1024);
props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");
```